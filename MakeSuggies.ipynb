{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "described-mistake",
   "metadata": {},
   "source": [
    "# Generate Interesting Improv bot suggestions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "union-liberty",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "import itertools\n",
    "import more_itertools\n",
    "import sys\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "stunning-brighton",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3500 words\n"
     ]
    }
   ],
   "source": [
    "def load_word_list(filename):\n",
    "    with open(filename) as f:\n",
    "        return [(line.strip(), idx) for idx, line in enumerate(f)]\n",
    "\n",
    "words = []\n",
    "words = words + load_word_list('google-10000-english-usa-no-swears-medium.txt')[:2000]\n",
    "words = words + load_word_list('google-10000-english-usa-no-swears-long.txt')[:1500]\n",
    "#words = words + load_word_list('google-10000-english-usa-no-swears-short.txt') # note: these are quite boring\n",
    "print('Loaded {} words'.format(len(words)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-korea",
   "metadata": {},
   "source": [
    "## Load Spacy for NLP\n",
    "This part can be slow, we'll load spacy and do part of speech tagging on all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "atomic-difficulty",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy_wordnet.wordnet_annotator import WordnetAnnotator \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")           # load model package \"en_core_web_sm\"\n",
    "nlp.add_pipe(WordnetAnnotator(nlp.lang), after='tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "aggressive-monthly",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5abb173d7014db0b0c6dbbcb836d5e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tagged_words = []\n",
    "for word, rank in tqdm(words):\n",
    "    doc = nlp(word)\n",
    "    # part of speech is most general, tag is more specific\n",
    "    tagged_words.append([word, doc[0].pos_, doc[0].tag_, rank])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "satisfied-singles",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load POS tags for reading\n",
    "pos_descriptions = defaultdict(str)\n",
    "with open('pos_tags.txt') as f:\n",
    "    for line in f:\n",
    "        parts = line.split(\"\\t\")\n",
    "        if len(parts) == 4:\n",
    "            pos_descriptions[parts[0]] = parts[3].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "organized-visit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group: NOUN - NN (noun, singular or mass) 1030\n",
      "search contact business service price state email music product system policy number support message software video school review order privacy company group research program hotel travel report member office design internet address phone shipping forum family website index today project \n",
      "\n",
      "Group: PROPN - NNP (noun, proper singular) 678\n",
      "health world january united center store national reserved south house county american download north white account digital reply december canada english windows thread october november series model forums march yahoo server april street standard mobile party login social august america \n",
      "\n",
      "Group: NOUN - NNS (noun, plural) 653\n",
      "services people products rights books links years items reviews games comments details terms hotels results states prices women pages sports members systems posts media pictures children students times sites events hours tools movies sales photos features articles issues users things \n",
      "\n",
      "Group: ADJ - JJ (adjective) 369\n",
      "other online public general great right local subject black special total current personal small previous private little advanced large human second medical complete legal recent young single possible major similar popular original archive green close common specific several short limited \n",
      "\n",
      "Group: VERB - VBN (verb, past participle) 199\n",
      "posted based found related provided required given become added listed updated powered written included received taken known designed created needed asked shown located featured wanted built involved rated selected joined expected proposed reported modified released detailed approved defined offered fixed \n",
      "\n",
      "Group: VERB - VBG (verb, gerund or present participle) 153\n",
      "using listing going looking working building making learning having living hosting reading getting doing running taking coming starting existing trying leading dating mailing buying moving playing showing setting selling giving ending thinking driving creating growing hearing finding saying talking missing \n",
      "\n",
      "Group: VERB - VB (verb, base form) 134\n",
      "click check think guide profile visit compare provide learn select register start create result write offer release enter drive cover watch choose receive remember increase build continue apply believe mature leave score follow allow cause answer improve ensure bring develop \n",
      "\n",
      "Group: ADV - RB (adverb) 123\n",
      "there first still around however really again never above always further already daily early usually together often later overall inside rather actually outside almost prior simply recently probably quite forward directly instead likely behind maybe finally fully highly perhaps easily \n",
      "\n",
      "Group: VERB - VBD (verb, past tense) 26\n",
      "called thought started wrote applied began worked became returned decided ended looked failed agreed happened enabled showed helped increased expressed indicated contributed understood concluded accredited predicted \n",
      "\n",
      "Group: VERB - VBZ (verb, 3rd person singular present) 26\n",
      "offers includes provides means makes comes takes seems contains allows requires gives follows appears wants feeds helps becomes remains knows starts begins continues indicates represents recommends \n",
      "\n",
      "Group: ADP - IN (conjunction, subordinating or preposition) 19\n",
      "about after through under before within between without during against below until along among across beyond towards toward throughout \n",
      "\n",
      "Group: PROPN - NNPS (noun, proper plural) 11\n",
      "keywords updates comics albums foods constitutes americans mechanisms democrats essentials christians \n",
      "\n",
      "Group: SCONJ - IN (conjunction, subordinating or preposition) 9\n",
      "because while since whether though although unless except despite \n",
      "\n",
      "Group: INTJ - UH (interjection) 8\n",
      "please quote welcome thanks homepage sorry hello anyway \n",
      "\n",
      "Group: PRON - NN (noun, singular or mass) 8\n",
      "someone anything anyone nothing everyone something everything everybody \n",
      "\n",
      "Group: ADJ - JJR (adjective, comparative) 7\n",
      "higher lower larger greater older easier smaller \n",
      "\n",
      "Group: ADJ - JJS (adjective, superlative) 7\n",
      "latest least highest largest lowest greatest newest \n",
      "\n",
      "Group: NUM - CD (cardinal number) 6\n",
      "three million seven eight billion twenty \n",
      "\n",
      "Group: PRON - PRP (pronoun, personal) 6\n",
      "yourself itself himself myself themselves ourselves \n",
      "\n",
      "Group: ADV - RBR (adverb, comparative) 5\n",
      "better longer earlier faster converter \n",
      "\n",
      "Group: VERB - MD (verb, modal auxiliary) 5\n",
      "would should could shall might \n",
      "\n",
      "Group: DET - DT (determiner) 4\n",
      "these those another every \n",
      "\n",
      "Group: X - FW (foreign word) 3\n",
      "forgot bytes gratis \n",
      "\n",
      "Group: CCONJ - CC (conjunction, coordinating) 2\n",
      "either neither \n",
      "\n",
      "Group: DET - WDT (wh-determiner) 2\n",
      "which whatever \n",
      "\n",
      "Group: VERB - VBP (verb, non-3rd person singular present) 2\n",
      "include thank \n",
      "\n",
      "Group: ADV - WRB (wh-adverb) 1\n",
      "where \n",
      "\n",
      "Group: AUX - VBG (verb, gerund or present participle) 1\n",
      "being \n",
      "\n",
      "Group: DET - PRP$ (pronoun, possessive) 1\n",
      "their \n",
      "\n",
      "Group: DET - WP$ (wh-pronoun, possessive) 1\n",
      "whose \n",
      "\n",
      "Group: X - LS (list item marker) 1\n",
      "overview \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Output words in each POS so we can see which ones we like\n",
    "def clamp(n, smallest, largest): return max(smallest, min(n, largest))\n",
    "\n",
    "words_by_pos = sorted(tagged_words, key=lambda w: (w[1], w[2]))\n",
    "by_pos = itertools.groupby(words_by_pos, lambda w: (w[1], w[2]))\n",
    "materialized_by_pos = [(group, list(items)) for group, items in by_pos]\n",
    "                        \n",
    "for group, items in sorted(materialized_by_pos, key=lambda p: -len(p[1])):\n",
    "    itemlist = list(items)\n",
    "    print('Group: ' + group[0] + ' - ' + group[1] + ' (' + pos_descriptions[group[1]] + ') ' + str(len(itemlist)))\n",
    "    \n",
    "    for item in more_itertools.take(40, itemlist):\n",
    "        sys.stdout.write(item[0])\n",
    "        sys.stdout.write(' ')\n",
    "    sys.stdout.write(\"\\n\\n\")\n",
    "\n",
    "sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "spare-guard",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter by POS\n",
    "filtered_words = [w for w in tagged_words if w[1] == 'NOUN' and w[2] == 'NN']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "several-permit",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aircraft', 'NOUN', 'NN', 1743]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trying it out\n",
    "import random\n",
    "filtered_words[random.randint(0, len(filtered_words) - 1)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "purple-nicholas",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 1030 suggestions\n"
     ]
    }
   ],
   "source": [
    "# Export to file\n",
    "text = \", \".join(['\"{}\"'.format(w[0]) for w in filtered_words])\n",
    "with open('suggies.txt', 'w') as f:\n",
    "    f.write(text)\n",
    "print(\"Wrote {} suggestions\".format(str(len(filtered_words))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
